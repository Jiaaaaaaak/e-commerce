import json
import os
import pickle
import numpy as np
import faiss
from dotenv import load_dotenv
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# è¨­å®šè·¯å¾‘
DATA_PATH = "data/faq.json"
VECTOR_DB_PATH = "data/vector_store/"

def get_embedding(text):
    """
    [Real Mode] å‘¼å« OpenAI å–å¾—çœŸå¯¦å‘é‡
    """
   
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def main():
    print(f"ğŸš€ [Real Mode] é–‹å§‹å»ºç«‹ RAG ç´¢å¼•ï¼Œè®€å–è³‡æ–™: {DATA_PATH}...")
    
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        faq_data = json.load(f)
    
    documents = []
    embeddings = []
    
    print(f"ğŸ“Š æ­£åœ¨å°‡ {len(faq_data)} ç­† FAQ è½‰ç‚ºå‘é‡ ...")
    for item in faq_data:
        # çµ„åˆå•é¡Œèˆ‡ç­”æ¡ˆï¼Œè®“èªæ„æ›´å®Œæ•´
        combined_text = f"å•é¡Œï¼š{item['question']} ç­”æ¡ˆï¼š{item['answer']}"
        
        try:
            vector = get_embedding(combined_text)
            embeddings.append(vector)
            documents.append(item)
        except Exception as e:
            print(f"âŒ è½‰æ›å¤±æ•—: {e}")
            return

    # å»ºç«‹ FAISS ç´¢å¼•
    if not embeddings:
        print("âš ï¸ æ²’æœ‰è³‡æ–™è¢«è½‰æ›ï¼Œè«‹æª¢æŸ¥ API Key æˆ–é¡åº¦ã€‚")
        return

    dimension = len(embeddings[0]) 
    index = faiss.IndexFlatL2(dimension)
    
    vector_np = np.array(embeddings).astype("float32")
    index.add(vector_np)
    
    # å­˜æª”
    if not os.path.exists(VECTOR_DB_PATH):
        os.makedirs(VECTOR_DB_PATH)
        
    faiss.write_index(index, os.path.join(VECTOR_DB_PATH, "index.faiss"))
    
    with open(os.path.join(VECTOR_DB_PATH, "metadata.pkl"), "wb") as f:
        pickle.dump(documents, f)
        
    print("âœ… çœŸå¯¦ RAG ç´¢å¼•å»ºç«‹å®Œæˆï¼æª”æ¡ˆå·²å„²å­˜ã€‚")

if __name__ == "__main__":
    main()